# 可擴充日誌系統 Logstash 建置 - 以 Debian 為例 #
## 基本介紹
#### Logstash 簡介
Logstash 是一套由 Jordan Sissel 所開源的自由軟體，以 Apache 2.0 的授權條款釋出。在整個日誌系統中，Logstash 可以視作一套日誌處理的引擎，其最強大的功能是負責"解析日誌"，將各種不同結構的資料進行結構化，輸出至 Elasticsearch 或是其它的儲存裝置。Logstash 可以運行在 JVM 的環境上，你可輕鬆的將它運行在各種系統平台，Linux、FreeBSD、Mac OS X，甚至是 Windows。Logstash 提供很多 Plugins，你可以直接將它套用到您的企業系統的架構中，如果不合使用或不支援您特殊的環境，您也可以自己撰寫 Plugin。Jordan 過去曾在 Google、Loggly、Heroku、DreamHost 工作，現在則任職於 Elasticsearch 公司 [來源1]。  
[來源1] [Welcome Jordan & Logstash. Aug 27, 2013](http://www.elasticsearch.com/blog/welcome-jordan-logstash/)
#### Elasticsearch 簡介
Elasticsearch 是一套基於 Lucene 上開發的即時搜尋引擎，由 Shay Banon 所開發，Shay 亦是 Compass 搜尋引擎的作者，他在開發 Compass 的過程中意識到，必須建立一個可以擴展 (Scalable) 的搜尋解決方案，並且可以提供一個通用的接口，讓除了 Java 以外的其他語言亦可使用，所以他開始對 Compass 進行重寫，其於 2010 年 2 月是出第一個版本，並取名叫 Elasticsearch，與 Lucene 一樣亦是採用 Apache 的授權條款釋出，在整個日誌系統上，它接收來自 Logstash 的日誌，並對其進行索引 (Indexing) 與搜索 (Searching)。Elasticsearch 至目前為止，穩定版已到 v1.3.1 的版本，已被各大公司、組織部署在 Production 的環境，Wikimedia 公告了其系統將全面轉換到 Elasticsearch 的聲明 [來源2]。  
[註] Compass - 一套亦是基於 Lucene 上開發 Java 的搜尋引擎框架，現在已不在維護。  
[來源2] [Wikimedia moving to Elasticsearch. Jan 6, 2014.](http://blog.wikimedia.org/2014/01/06/wikimedia-moving-to-elasticsearch/)

>『全文檢索是一件很繁雜的事，特別是對各種語言在斷詞、斷字上的支援』

## 建置架構
我們會示範兩種建置的系統架構，第一種為基本架構，主要是為了讓大家熟悉 Logstash 本身，也初步了解簡單的集中日誌的架構；而第二種架構為可擴充性架構，是為讓大家了解怎麼讓 Logstash 動態展延，也更貼近真實世界的大規模部署。
* 第一種：  
  Nodes (Log Shippers) -> Logstash (Central) -> Elasticsearch (Indexing)   

* 第二種：  
  Nodes (Log Shippers) -> Redis (Broker) -> Logstash (Central) -> Elasticsearch (Indexing)

## 事前準備
#### 更新系統並安裝基本套件
```bash
$ sudo aptitude update && sudo aptitude -y dist-upgrade
$ sudo aptitude install wget curl
```
## 開始安裝
#### 使用套件庫安裝
```bash
$ wget -qO - http://packages.elasticsearch.org/GPG-KEY-elasticsearch | sudo apt-key add -
$ echo 'deb http://packages.elasticsearch.org/elasticsearch/1.3/debian stable main' | sudo tee -a /etc/apt/sources.list.d/elasticsearch.list
$ echo 'deb http://packages.elasticsearch.org/logstash/1.4/debian stable main' | sudo tee -a /etc/apt/sources.list.d/logstash.list
$ sudo aptitude update && sudo aptitude install elasticsearch logstash 
```
使用 APT 套件庫安裝的好處就是它會在安裝的過程中，會幫你將相依性的套件安裝起來。在安裝 Logstash 的過程中，若你的系統上沒有安裝 JRE 的環境，APT 會幫你帶上 java 的套件一併安裝，若您是採用手動安裝的方式，再記得要安裝 JRE 的套件。

#### 手動下載套件
```bash
$ wget -c 'https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-1.3.1.deb' 'https://download.elasticsearch.org/logstash/logstash/packages/debian/logstash_1.4.2-1-2c0f5a1_all.deb'
```

> Logstash 在官方下載頁面上有分兩種版本，一種是核心(Core)版本，一種為社群版本，核心版本就是含其 Plugins 皆由 Elasticsearch 官方支援，而社群版本則是會納入那些官方不支援的 Plugins。

在 Elasticsearch 安裝完之後，運行下面指令查看服務是否正確啟動，如果有正確運作應會返回一串 JSON 資訊：
```bash
$ curl -X GET http://localhost:9200
{
  "status" : 200,
  "name" : "Jens Meilleur Slap Shot",
  "version" : {
    "number" : "1.3.1",
    "build_hash" : "2de6dc5268c32fb49b205233c138d93aaf772015",
    "build_timestamp" : "2014-07-28T14:45:15Z",
    "build_snapshot" : false,
    "lucene_version" : "4.9"
  },
  "tagline" : "You Know, for Search"
}
```
啟動 Logstash 服務
```
sudo /etc/init.d/logstash start
```
Logstash 會安裝至 /opt/logstash/ 目錄底下
/var/log/logstash
logstash.err  logstash.log  logstash.stdout  logstash-web.err  logstash-web.stdout

Elasticsearch 會安裝至
/etc/elasticsearch
elasticsearch.yml  logging.yml
/var/log/elasticsearch
elasticsearch_index_indexing_slowlog.log  elasticsearch_index_search_slowlog.log  elasticsearch.log

## 安裝 Kibana
#### 套件安裝 Kibana
如果你是使用套件安裝 Logstash 的方式，則 Kibana 已經被包在套件裡一併安裝在系統上了，你只需要啟動它，輸入
```
$ sudo /etc/init.d/logstash-web start
```
#### 手動安裝 Kibana
```
$ wget -c 'https://download.elasticsearch.org/kibana/kibana/kibana-3.1.0.tar.gz'
$ tar vxf kibana-3.1.0.tar.gz
```
打開你的瀏覽器，輸入 localhost:9292，你應該會看到 Kibana 的歡迎畫面，如下圖所示：


另外，Kibana 提供一個預設的儀表板(Dashboard)，你可以直接點選它的連結，去感受 Kibana 帶來的良好日誌查詢體驗。不過如果你想要使用它預設的配置，Kibana 也提供另外三種選項讓你選擇，分別為範例儀表板 (Sample Dashboard)、未配置的儀表板(Unconfigured Dashboard)、空白儀表板(Blank Dashboard)。
* 範例儀表板 (Sample Dashboard) - 提供一些預配置，並說明它的用途。(給第一次使用 Kibana 的使用者使用)
* 未配置的儀表板(Unconfigured Dashboard) - 沒有載入資料，待你配置完後在進行載入。(給準備自訂儀表板的人使用者使用)
* 空白儀表板(Blank Dashboard) - 完全客制化自己的儀表板。(給已經很熟悉的使用者使用)

> 如果你發現你的 Kibana 畫面有問題，有某些功能無法正常使用，這有可能是你使用的瀏覽器版本無法支援某些 JavaScript 的前端框架，建議你更新你的瀏覽器版本，我在這裡推薦你使用 Chrome 或 Firefox。
* Google Chrome [https://www.google.com/intl/en/chrome/browser/](https://www.google.com/intl/en/chrome/browser/)
* Mozilla Firefox [https://www.mozilla.org/en-US/firefox/new/](https://www.mozilla.org/en-US/firefox/new/)

## Logstash 設定檔
Logstash 的設定檔主要分成三個部分，分別為 inoput、filter 及 output
```bash
input {

}

filter {
}

output {
}
```

模組插件(Plugin)
在 Logstash 官方及社群的努力下，Logstash 已經提供了眾多的 Plugins，來適應各種不同的需求及環境，你可以輕易的將其建置進你的維運環境中，提高對日誌的管理能力。

Plugin 的里程碑(Milestone) 主要分成 0, 1, 2, 3 個
分別代表該 Plugin 的成熟度。

Plugin Milestones [https://github.com/elasticsearch/logstash/blob/master/docs/plugin-milestones.md](https://github.com/elasticsearch/logstash/blob/master/docs/plugin-milestones.md)

## 建置第一種架構
讓我們在建置前，再來回顧一下第一種架構，如同前面所述，第一種架構是為了讓大家熟悉 Logstash 本身，也初步了解簡單的集中日誌的架構。

首先，我們了解一下名詞所代表的意思，Log Shipper 為日誌的發送方，即日誌原始存放的位置，而 Central 則為日誌的接收方，也就是要將日誌集中的地方，對於 Central 來說 Log shipper 就是日誌的來源，在 Central 接收到大量的日誌後，先對其進行結構化，最後在輸出至 Elasticsearch 來對日誌進行索引，以方便後續的查詢。
* 第一種：  
  Nodes (Log Shippers) -> Logstash (Central) -> Elasticsearch (Indexing)   

在這個架構下，最好的實作環境是使用三台伺服器，建議你可以使用虛擬化的技術開三台虛擬機出來，當然你也可以都將它們安裝在同一台。另外，我也預計你已經將 Logstash 安裝在 Shipper 與 Central 的系統下了，而第三台伺服器上只單純安裝 Elasticsearch。很簡單，我也相信大家早就駕輕就熟了，最後為了方便識別在 Shipper 與 Central 上的 Logstash 設定檔，我們先約定好 Shipper 上的叫做 shipper.conf，Central 上的叫做 central.conf，都各別存放在各自的系統的 /etc/logstash/ 路徑下。
```
input {
  # 使用 file 模組插件
  file {
    
  }
}
```
我建議大家使用 logstash 作為 shipper，不過在很多因素考量下，效能、安全
你仍可使用系統原生的 syslog daemon


在 Shipper 設定檔上，在指定 host 上儘量使用 ip address，而不要使用 domain name，它會向 DNS 伺服器不斷查詢，

因為 MongoDB 本身在資料的儲存結構上
改存成純文字檔的方式，再每天依據日期用 gzip 壓起來封存會是一個比較合適的選擇。

> Log Shipper 也有人叫 Forwarder 或 Agent，但我覺得 Shipper 是一個較佳的稱呼

## 建置第二種架構
在經過第一種架構的洗禮之後，想必各位對 Logstash 都有一定的了解了，但我們的目標使要解決大量的日誌集中管理的問題，
在大規模的分散式部署上
中繼站(Broker)
在本次的實作上，我們是使用 Redis 做為我們的 Broker 來解決跨機房之間傳送日誌時，可能會掉大量資料的問題，是的，即便你是使用 TCP 來傳送，當然除了 Redis 之外，你還有 RabbitMQ、ZeroMQ 等其它訊息佇列的技術可以選擇。

> 訊息佇列(Message Queue)
> 依照先進先出 FIFO (First In, First Out) 的概念

* 第二種：  
  Nodes (Log Shippers) -> Redis (Broker) -> Logstash (Central) -> Elasticsearch (Indexing)

#### Shipper 設定檔

#### Central 設定檔

#### Elasticsearch 設定檔

## 使用 Puppet 自動化建置 Logstash
#### Puppet 簡介


#### puppet-logstash 模組
非常幸運的，Elasticsearch 已經為 logstash 寫好了 Puppet 的模組，我們只需要直接使用它


## 使用 Docker


## 相關程式碼
Elasticsearch、Logstash、Kibana 其程式碼皆託管在 GitHub 上，你可以透過下面的網址去查看它們的程式碼。
* Logstash on GitHub [https://github.com/elasticsearch/logstash](https://github.com/elasticsearch/logstash)
* Elasticsearch on GitHub [https://github.com/elasticsearch/elasticsearch](https://github.com/elasticsearch/elasticsearch)
* Kibana on GitHub [https://github.com/elasticsearch/kibana](https://github.com/elasticsearch/kibana)
* puppet-logstash on GitHub [https://github.com/elasticsearch/puppet-logstash](https://github.com/elasticsearch/puppet-logstash)
## 參與社群討論
分享您的使用經驗
* logstash-users - Google Groups [https://groups.google.com/d/forum/logstash-users](https://groups.google.com/d/forum/logstash-users)
* Logstash.TW on Facebook [http://logstash.tw](http://logstash.tw)


## 聯絡我
如果你有任何問題或錯誤回報，你可以透過 Email 向我們聯繫，我們的信箱是